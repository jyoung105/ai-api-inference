{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference through Together.ai\n",
    "\n",
    "<img src=\"../asset/togetherai.png\" width=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "TOGETHER_API_KEY = TOGETHER_API_KEY\n",
    "BASE_URL = \"https://api.together.xyz/v1\"\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=TOGETHER_API_KEY,\n",
    "    base_url=BASE_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a travel agent. Be descriptive and helpful.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about San Francisco\"},\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(f\"Took {time.time()-start:.2f} secs\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a travel agent. Be descriptive and helpful.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about San Francisco\"},\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(f\"Took {time.time()-start:.2f} secs\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a travel agent. Be descriptive and helpful.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about San Francisco\"},\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(f\"Took {time.time()-start:.2f} secs\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Together inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from together import Together\n",
    "\n",
    "TOGETHER_API_KEY = TOGETHER_API_KEY\n",
    "\n",
    "client = Together(api_key=TOGETHER_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from together import Together\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What are some fun things to do in New York?\"}],\n",
    ")\n",
    "\n",
    "print(f\"Took {time.time()-start:.2f} secs\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from together import Together\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"What are some fun things to do in New York?\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"You could go to the Empire State Building!\"},\n",
    "      {\"role\": \"user\", \"content\": \"That sounds fun! Where is it?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"Took {time.time()-start:.2f} secs\")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mistralai/Mixtral-8x7B-Instruct-v0.1, mistralai/Mistral-7B-Instruct-v0.1, togethercomputer/CodeLlama-34b-Instruct\n",
    "\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "import time\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url = \"https://api.together.xyz/v1\",\n",
    "    api_key = TOGETHER_API_KEY,\n",
    ")\n",
    "\n",
    "tools = [\n",
    "  {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"get_current_weather\",\n",
    "      \"description\": \"Get the current weather in a given location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The city and state, e.g. San Francisco, CA\"\n",
    "          },\n",
    "          \"unit\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\n",
    "              \"celsius\",\n",
    "              \"fahrenheit\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that can access external functions. The responses from these function calls will be appended to this dialogue. Please provide responses based on the information from these function calls.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the current temperature of New York, San Francisco and Chicago?\"}\n",
    "]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    ")\n",
    "\n",
    "print(f\"Took {time.time()-start:.2f} secs\")\n",
    "print(json.dumps(response.choices[0].message.model_dump()['tool_calls'], indent=2))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
